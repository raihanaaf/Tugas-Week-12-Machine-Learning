{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "xoSobalujOBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformasi Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "-EU_RBn0kNXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 Dataset\n",
        "batch_size = 32\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XI8n5w3kPeO",
        "outputId": "77b728f4-ee31-44cd-d107-6a600836133f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train dataset menjadi train dan validation\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "JbK7OUetkSVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Arsitektur\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, kernel_size=3, pooling_type='max'):\n",
        "        super(CNN, self).__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=kernel_size, padding=padding)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        if pooling_type == 'max':\n",
        "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        elif pooling_type == 'avg':\n",
        "            self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DVllS7YjkVnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dan Evaluasi\n",
        "def train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs, early_stopping_patience=10):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = CNN(kernel_size=kernel_size, pooling_type=pooling_type).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    if optimizer_type == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    elif optimizer_type == 'RMSProp':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
        "    elif optimizer_type == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Learning Rate Scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=False)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(f\"Evaluating with params: {{'epochs': {epochs}, 'kernel_size': {kernel_size}, 'optimizer_type': '{optimizer_type}', 'pooling_type': '{pooling_type}'}}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Step\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation Step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early Stopping\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stopping_patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # Evaluasi Akurasi pada Test Dataset\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Eksperimen dengan Semua Kombinasi Parameter\n",
        "kernel_sizes = [3, 5, 7]\n",
        "pooling_types = ['max', 'avg']\n",
        "optimizers = ['SGD', 'RMSProp', 'Adam']\n",
        "epoch_list = [5, 50, 100, 250, 350]\n",
        "\n",
        "results = []\n",
        "\n",
        "for kernel_size in kernel_sizes:\n",
        "    for pooling_type in pooling_types:\n",
        "        for optimizer in optimizers:\n",
        "            for epochs in epoch_list:\n",
        "                print(f\"Running experiment with kernel_size={kernel_size}, pooling_type={pooling_type}, optimizer={optimizer}, epochs={epochs}\")\n",
        "                accuracy = train_and_evaluate(kernel_size, pooling_type, optimizer, epochs, early_stopping_patience=10)\n",
        "                results.append((kernel_size, pooling_type, optimizer, epochs, accuracy))\n",
        "\n",
        "# Menampilkan Hasil Akhir\n",
        "print(\"\\nHasil Akhir Eksperimen:\")\n",
        "for result in results:\n",
        "    print(f\"Kernel Size: {result[0]}, Pooling: {result[1]}, Optimizer: {result[2]}, Epochs: {result[3]}, Accuracy: {result[4]:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1dIdBjUka-L",
        "outputId": "266574dc-7f63-49f4-b1ca-fc29ee244a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=SGD, epochs=5\n",
            "Evaluating with params: {'epochs': 5, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'max'}\n",
            "Epoch 1/5, Loss: 1.6535, Val Loss: 1.2997\n",
            "Epoch 2/5, Loss: 1.2509, Val Loss: 1.0239\n",
            "Epoch 3/5, Loss: 1.0786, Val Loss: 0.9654\n",
            "Epoch 4/5, Loss: 0.9817, Val Loss: 0.9008\n",
            "Epoch 5/5, Loss: 0.8940, Val Loss: 0.9055\n",
            "Accuracy: 69.18%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=SGD, epochs=50\n",
            "Evaluating with params: {'epochs': 50, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'max'}\n",
            "Epoch 1/50, Loss: 1.6518, Val Loss: 1.2830\n",
            "Epoch 2/50, Loss: 1.2485, Val Loss: 1.1055\n",
            "Epoch 3/50, Loss: 1.0867, Val Loss: 0.9638\n",
            "Epoch 4/50, Loss: 0.9748, Val Loss: 0.9195\n",
            "Epoch 5/50, Loss: 0.8919, Val Loss: 0.8581\n",
            "Epoch 6/50, Loss: 0.8157, Val Loss: 0.8519\n",
            "Epoch 7/50, Loss: 0.7554, Val Loss: 0.8516\n",
            "Epoch 8/50, Loss: 0.7017, Val Loss: 0.8948\n",
            "Epoch 9/50, Loss: 0.6514, Val Loss: 0.8833\n",
            "Epoch 10/50, Loss: 0.6120, Val Loss: 0.9389\n",
            "Epoch 11/50, Loss: 0.5782, Val Loss: 0.8738\n",
            "Epoch 12/50, Loss: 0.5435, Val Loss: 0.9408\n",
            "Epoch 13/50, Loss: 0.5223, Val Loss: 0.9641\n",
            "Epoch 14/50, Loss: 0.3752, Val Loss: 0.9542\n",
            "Epoch 15/50, Loss: 0.3287, Val Loss: 0.9839\n",
            "Epoch 16/50, Loss: 0.2918, Val Loss: 1.0215\n",
            "Epoch 17/50, Loss: 0.2716, Val Loss: 1.0412\n",
            "Early stopping triggered.\n",
            "Accuracy: 72.85%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=SGD, epochs=100\n",
            "Evaluating with params: {'epochs': 100, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'max'}\n",
            "Epoch 1/100, Loss: 1.6518, Val Loss: 1.3069\n",
            "Epoch 2/100, Loss: 1.2807, Val Loss: 1.1087\n",
            "Epoch 3/100, Loss: 1.1107, Val Loss: 0.9829\n",
            "Epoch 4/100, Loss: 0.9929, Val Loss: 0.9105\n",
            "Epoch 5/100, Loss: 0.8971, Val Loss: 0.8968\n",
            "Epoch 6/100, Loss: 0.8281, Val Loss: 0.9047\n",
            "Epoch 7/100, Loss: 0.7660, Val Loss: 0.8759\n",
            "Epoch 8/100, Loss: 0.7130, Val Loss: 0.8676\n",
            "Epoch 9/100, Loss: 0.6641, Val Loss: 0.9268\n",
            "Epoch 10/100, Loss: 0.6256, Val Loss: 0.9074\n",
            "Epoch 11/100, Loss: 0.5810, Val Loss: 0.8934\n",
            "Epoch 12/100, Loss: 0.5560, Val Loss: 0.9353\n",
            "Epoch 13/100, Loss: 0.5235, Val Loss: 0.9990\n",
            "Epoch 14/100, Loss: 0.4964, Val Loss: 1.0039\n",
            "Epoch 15/100, Loss: 0.3621, Val Loss: 0.9838\n",
            "Epoch 16/100, Loss: 0.3063, Val Loss: 1.0213\n",
            "Epoch 17/100, Loss: 0.2823, Val Loss: 1.0794\n",
            "Epoch 18/100, Loss: 0.2618, Val Loss: 1.0849\n",
            "Early stopping triggered.\n",
            "Accuracy: 73.42%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=SGD, epochs=250\n",
            "Evaluating with params: {'epochs': 250, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'max'}\n",
            "Epoch 1/250, Loss: 1.6409, Val Loss: 1.2527\n",
            "Epoch 2/250, Loss: 1.2313, Val Loss: 1.0358\n",
            "Epoch 3/250, Loss: 1.0682, Val Loss: 0.9591\n",
            "Epoch 4/250, Loss: 0.9587, Val Loss: 0.9000\n",
            "Epoch 5/250, Loss: 0.8719, Val Loss: 0.8767\n",
            "Epoch 6/250, Loss: 0.8011, Val Loss: 0.8608\n",
            "Epoch 7/250, Loss: 0.7409, Val Loss: 0.8485\n",
            "Epoch 8/250, Loss: 0.6850, Val Loss: 0.8648\n",
            "Epoch 9/250, Loss: 0.6458, Val Loss: 0.8884\n",
            "Epoch 10/250, Loss: 0.5997, Val Loss: 0.8803\n",
            "Epoch 11/250, Loss: 0.5677, Val Loss: 0.8662\n",
            "Epoch 12/250, Loss: 0.5339, Val Loss: 0.9216\n",
            "Epoch 13/250, Loss: 0.5052, Val Loss: 0.9562\n",
            "Epoch 14/250, Loss: 0.3636, Val Loss: 0.9711\n",
            "Epoch 15/250, Loss: 0.3110, Val Loss: 0.9722\n",
            "Epoch 16/250, Loss: 0.2825, Val Loss: 1.0266\n",
            "Epoch 17/250, Loss: 0.2605, Val Loss: 1.0641\n",
            "Early stopping triggered.\n",
            "Accuracy: 73.69%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=SGD, epochs=350\n",
            "Evaluating with params: {'epochs': 350, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'max'}\n",
            "Epoch 1/350, Loss: 1.6185, Val Loss: 1.2748\n",
            "Epoch 2/350, Loss: 1.2449, Val Loss: 1.0464\n",
            "Epoch 3/350, Loss: 1.0905, Val Loss: 0.9732\n",
            "Epoch 4/350, Loss: 0.9765, Val Loss: 0.9300\n",
            "Epoch 5/350, Loss: 0.8867, Val Loss: 0.8871\n",
            "Epoch 6/350, Loss: 0.8212, Val Loss: 0.8999\n",
            "Epoch 7/350, Loss: 0.7635, Val Loss: 0.8928\n",
            "Epoch 8/350, Loss: 0.7014, Val Loss: 0.8842\n",
            "Epoch 9/350, Loss: 0.6566, Val Loss: 0.8763\n",
            "Epoch 10/350, Loss: 0.6205, Val Loss: 0.8580\n",
            "Epoch 11/350, Loss: 0.5750, Val Loss: 0.9351\n",
            "Epoch 12/350, Loss: 0.5495, Val Loss: 0.9628\n",
            "Epoch 13/350, Loss: 0.5143, Val Loss: 0.9100\n",
            "Epoch 14/350, Loss: 0.4937, Val Loss: 0.9567\n",
            "Epoch 15/350, Loss: 0.4797, Val Loss: 1.0562\n",
            "Epoch 16/350, Loss: 0.4561, Val Loss: 1.0841\n",
            "Epoch 17/350, Loss: 0.3251, Val Loss: 1.0132\n",
            "Epoch 18/350, Loss: 0.2761, Val Loss: 1.0601\n",
            "Epoch 19/350, Loss: 0.2514, Val Loss: 1.1064\n",
            "Epoch 20/350, Loss: 0.2301, Val Loss: 1.1733\n",
            "Early stopping triggered.\n",
            "Accuracy: 73.09%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=RMSProp, epochs=5\n",
            "Evaluating with params: {'epochs': 5, 'kernel_size': 3, 'optimizer_type': 'RMSProp', 'pooling_type': 'max'}\n",
            "Epoch 1/5, Loss: 4.8242, Val Loss: 1.9459\n",
            "Epoch 2/5, Loss: 1.9435, Val Loss: 1.7500\n",
            "Epoch 3/5, Loss: 1.8352, Val Loss: 1.7724\n",
            "Epoch 4/5, Loss: 1.8203, Val Loss: 1.6763\n",
            "Epoch 5/5, Loss: 1.7907, Val Loss: 1.6647\n",
            "Accuracy: 40.05%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=RMSProp, epochs=50\n",
            "Evaluating with params: {'epochs': 50, 'kernel_size': 3, 'optimizer_type': 'RMSProp', 'pooling_type': 'max'}\n",
            "Epoch 1/50, Loss: 3.4436, Val Loss: 1.8190\n",
            "Epoch 2/50, Loss: 1.8814, Val Loss: 1.7342\n",
            "Epoch 3/50, Loss: 1.8220, Val Loss: 1.6158\n",
            "Epoch 4/50, Loss: 1.7837, Val Loss: 1.6128\n",
            "Epoch 5/50, Loss: 1.7537, Val Loss: 1.6199\n",
            "Epoch 6/50, Loss: 1.7625, Val Loss: 1.9724\n",
            "Epoch 7/50, Loss: 1.7363, Val Loss: 1.6459\n",
            "Epoch 8/50, Loss: 1.7293, Val Loss: 1.6031\n",
            "Epoch 9/50, Loss: 1.7324, Val Loss: 1.6134\n",
            "Epoch 10/50, Loss: 1.7153, Val Loss: 1.6503\n",
            "Epoch 11/50, Loss: 1.7227, Val Loss: 1.5975\n",
            "Epoch 12/50, Loss: 1.7379, Val Loss: 1.7130\n",
            "Epoch 13/50, Loss: 1.7327, Val Loss: 1.6001\n",
            "Epoch 14/50, Loss: 1.7207, Val Loss: 1.6954\n",
            "Epoch 15/50, Loss: 1.7411, Val Loss: 1.5967\n",
            "Epoch 16/50, Loss: 1.7304, Val Loss: 1.6055\n",
            "Epoch 17/50, Loss: 1.7533, Val Loss: 1.5586\n",
            "Epoch 18/50, Loss: 1.7438, Val Loss: 1.5884\n",
            "Epoch 19/50, Loss: 1.7400, Val Loss: 1.5961\n",
            "Epoch 20/50, Loss: 1.7616, Val Loss: 1.6179\n",
            "Epoch 21/50, Loss: 1.7258, Val Loss: 1.7350\n",
            "Epoch 22/50, Loss: 1.7412, Val Loss: 1.7611\n",
            "Epoch 23/50, Loss: 1.7618, Val Loss: 1.6666\n",
            "Epoch 24/50, Loss: 1.6147, Val Loss: 1.4892\n",
            "Epoch 25/50, Loss: 1.5825, Val Loss: 1.4896\n",
            "Epoch 26/50, Loss: 1.5777, Val Loss: 1.4787\n",
            "Epoch 27/50, Loss: 1.5637, Val Loss: 1.5118\n",
            "Epoch 28/50, Loss: 1.5503, Val Loss: 1.5776\n",
            "Epoch 29/50, Loss: 1.5617, Val Loss: 1.5275\n",
            "Epoch 30/50, Loss: 1.5531, Val Loss: 1.5072\n",
            "Epoch 31/50, Loss: 1.5343, Val Loss: 1.4873\n",
            "Epoch 32/50, Loss: 1.5542, Val Loss: 1.5038\n",
            "Epoch 33/50, Loss: 1.4640, Val Loss: 1.4303\n",
            "Epoch 34/50, Loss: 1.4556, Val Loss: 1.4681\n",
            "Epoch 35/50, Loss: 1.4505, Val Loss: 1.4342\n",
            "Epoch 36/50, Loss: 1.4391, Val Loss: 1.4252\n",
            "Epoch 37/50, Loss: 1.4368, Val Loss: 1.4178\n",
            "Epoch 38/50, Loss: 1.4360, Val Loss: 1.4157\n",
            "Epoch 39/50, Loss: 1.4358, Val Loss: 1.4404\n",
            "Epoch 40/50, Loss: 1.4320, Val Loss: 1.4329\n",
            "Epoch 41/50, Loss: 1.4266, Val Loss: 1.3900\n",
            "Epoch 42/50, Loss: 1.4159, Val Loss: 1.4018\n",
            "Epoch 43/50, Loss: 1.4144, Val Loss: 1.4127\n",
            "Epoch 44/50, Loss: 1.4197, Val Loss: 1.4324\n",
            "Epoch 45/50, Loss: 1.4198, Val Loss: 1.4241\n",
            "Epoch 46/50, Loss: 1.4124, Val Loss: 1.4435\n",
            "Epoch 47/50, Loss: 1.4116, Val Loss: 1.4177\n",
            "Epoch 48/50, Loss: 1.3599, Val Loss: 1.3928\n",
            "Epoch 49/50, Loss: 1.3452, Val Loss: 1.3889\n",
            "Epoch 50/50, Loss: 1.3513, Val Loss: 1.4038\n",
            "Accuracy: 52.66%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=RMSProp, epochs=100\n",
            "Evaluating with params: {'epochs': 100, 'kernel_size': 3, 'optimizer_type': 'RMSProp', 'pooling_type': 'max'}\n",
            "Epoch 1/100, Loss: 3.1136, Val Loss: 1.9440\n",
            "Epoch 2/100, Loss: 1.9412, Val Loss: 1.7338\n",
            "Epoch 3/100, Loss: 1.8916, Val Loss: 2.0686\n",
            "Epoch 4/100, Loss: 1.8987, Val Loss: 1.6873\n",
            "Epoch 5/100, Loss: 1.8235, Val Loss: 1.6593\n",
            "Epoch 6/100, Loss: 1.8001, Val Loss: 1.6893\n",
            "Epoch 7/100, Loss: 1.7460, Val Loss: 1.6631\n",
            "Epoch 8/100, Loss: 1.7563, Val Loss: 1.6114\n",
            "Epoch 9/100, Loss: 1.7399, Val Loss: 1.6200\n",
            "Epoch 10/100, Loss: 1.7534, Val Loss: 1.6033\n",
            "Epoch 11/100, Loss: 1.7322, Val Loss: 1.5535\n",
            "Epoch 12/100, Loss: 1.7233, Val Loss: 1.6410\n",
            "Epoch 13/100, Loss: 1.7240, Val Loss: 1.6272\n",
            "Epoch 14/100, Loss: 1.7324, Val Loss: 1.6139\n",
            "Epoch 15/100, Loss: 1.7224, Val Loss: 1.5766\n",
            "Epoch 16/100, Loss: 1.7342, Val Loss: 1.6368\n",
            "Epoch 17/100, Loss: 1.7245, Val Loss: 1.6960\n",
            "Epoch 18/100, Loss: 1.6158, Val Loss: 1.5154\n",
            "Epoch 19/100, Loss: 1.5795, Val Loss: 1.5322\n",
            "Epoch 20/100, Loss: 1.5665, Val Loss: 1.4739\n",
            "Epoch 21/100, Loss: 1.5572, Val Loss: 1.4719\n",
            "Epoch 22/100, Loss: 1.5509, Val Loss: 1.4926\n",
            "Epoch 23/100, Loss: 1.5434, Val Loss: 1.4858\n",
            "Epoch 24/100, Loss: 1.5396, Val Loss: 1.4250\n",
            "Epoch 25/100, Loss: 1.5316, Val Loss: 1.5222\n",
            "Epoch 26/100, Loss: 1.5333, Val Loss: 1.4544\n",
            "Epoch 27/100, Loss: 1.5288, Val Loss: 1.4861\n",
            "Epoch 28/100, Loss: 1.5235, Val Loss: 1.4602\n",
            "Epoch 29/100, Loss: 1.5231, Val Loss: 1.4701\n",
            "Epoch 30/100, Loss: 1.5148, Val Loss: 1.4607\n",
            "Epoch 31/100, Loss: 1.4474, Val Loss: 1.4063\n",
            "Epoch 32/100, Loss: 1.4292, Val Loss: 1.4104\n",
            "Epoch 33/100, Loss: 1.4245, Val Loss: 1.4414\n",
            "Epoch 34/100, Loss: 1.4155, Val Loss: 1.4152\n",
            "Epoch 35/100, Loss: 1.4130, Val Loss: 1.3999\n",
            "Epoch 36/100, Loss: 1.4070, Val Loss: 1.4119\n",
            "Epoch 37/100, Loss: 1.4045, Val Loss: 1.4278\n",
            "Epoch 38/100, Loss: 1.4038, Val Loss: 1.4273\n",
            "Epoch 39/100, Loss: 1.4004, Val Loss: 1.4211\n",
            "Epoch 40/100, Loss: 1.3970, Val Loss: 1.4167\n",
            "Epoch 41/100, Loss: 1.3928, Val Loss: 1.4107\n",
            "Epoch 42/100, Loss: 1.3411, Val Loss: 1.4053\n",
            "Epoch 43/100, Loss: 1.3391, Val Loss: 1.4149\n",
            "Epoch 44/100, Loss: 1.3357, Val Loss: 1.4291\n",
            "Epoch 45/100, Loss: 1.3384, Val Loss: 1.4392\n",
            "Early stopping triggered.\n",
            "Accuracy: 52.48%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=RMSProp, epochs=250\n",
            "Evaluating with params: {'epochs': 250, 'kernel_size': 3, 'optimizer_type': 'RMSProp', 'pooling_type': 'max'}\n",
            "Epoch 1/250, Loss: 4.8198, Val Loss: 1.9184\n",
            "Epoch 2/250, Loss: 1.9494, Val Loss: 1.7453\n",
            "Epoch 3/250, Loss: 1.8765, Val Loss: 1.6883\n",
            "Epoch 4/250, Loss: 1.8251, Val Loss: 1.8064\n",
            "Epoch 5/250, Loss: 1.7777, Val Loss: 1.6904\n",
            "Epoch 6/250, Loss: 1.8023, Val Loss: 1.6319\n",
            "Epoch 7/250, Loss: 1.7601, Val Loss: 1.6731\n",
            "Epoch 8/250, Loss: 1.7445, Val Loss: 1.6357\n",
            "Epoch 9/250, Loss: 1.7396, Val Loss: 1.7313\n",
            "Epoch 10/250, Loss: 1.7576, Val Loss: 1.6097\n",
            "Epoch 11/250, Loss: 1.7401, Val Loss: 1.6038\n",
            "Epoch 12/250, Loss: 1.7466, Val Loss: 1.5982\n",
            "Epoch 13/250, Loss: 1.7528, Val Loss: 1.6289\n",
            "Epoch 14/250, Loss: 1.7763, Val Loss: 1.6143\n",
            "Epoch 15/250, Loss: 1.7314, Val Loss: 1.6255\n",
            "Epoch 16/250, Loss: 1.7440, Val Loss: 1.6781\n",
            "Epoch 17/250, Loss: 1.7425, Val Loss: 1.6185\n",
            "Epoch 18/250, Loss: 1.7482, Val Loss: 1.6433\n",
            "Epoch 19/250, Loss: 1.6072, Val Loss: 1.5023\n",
            "Epoch 20/250, Loss: 1.5900, Val Loss: 1.4699\n",
            "Epoch 21/250, Loss: 1.5725, Val Loss: 1.4484\n",
            "Epoch 22/250, Loss: 1.5635, Val Loss: 1.4619\n",
            "Epoch 23/250, Loss: 1.5511, Val Loss: 1.4509\n",
            "Epoch 24/250, Loss: 1.5369, Val Loss: 1.5244\n",
            "Epoch 25/250, Loss: 1.5310, Val Loss: 1.4667\n",
            "Epoch 26/250, Loss: 1.5290, Val Loss: 1.4366\n",
            "Epoch 27/250, Loss: 1.5248, Val Loss: 1.4901\n",
            "Epoch 28/250, Loss: 1.5212, Val Loss: 1.4579\n",
            "Epoch 29/250, Loss: 1.5189, Val Loss: 1.4329\n",
            "Epoch 30/250, Loss: 1.5172, Val Loss: 1.4262\n",
            "Epoch 31/250, Loss: 1.5146, Val Loss: 1.4284\n",
            "Epoch 32/250, Loss: 1.4985, Val Loss: 1.4128\n",
            "Epoch 33/250, Loss: 1.5069, Val Loss: 1.4213\n",
            "Epoch 34/250, Loss: 1.5044, Val Loss: 1.4309\n",
            "Epoch 35/250, Loss: 1.4992, Val Loss: 1.4384\n",
            "Epoch 36/250, Loss: 1.4997, Val Loss: 1.4465\n",
            "Epoch 37/250, Loss: 1.4865, Val Loss: 1.4451\n",
            "Epoch 38/250, Loss: 1.4996, Val Loss: 1.4529\n",
            "Epoch 39/250, Loss: 1.4080, Val Loss: 1.3850\n",
            "Epoch 40/250, Loss: 1.3874, Val Loss: 1.3826\n",
            "Epoch 41/250, Loss: 1.3840, Val Loss: 1.3890\n",
            "Epoch 42/250, Loss: 1.3756, Val Loss: 1.4081\n",
            "Epoch 43/250, Loss: 1.3805, Val Loss: 1.3748\n",
            "Epoch 44/250, Loss: 1.3683, Val Loss: 1.4022\n",
            "Epoch 45/250, Loss: 1.3656, Val Loss: 1.3811\n",
            "Epoch 46/250, Loss: 1.3697, Val Loss: 1.3895\n",
            "Epoch 47/250, Loss: 1.3632, Val Loss: 1.4286\n",
            "Epoch 48/250, Loss: 1.3563, Val Loss: 1.3808\n",
            "Epoch 49/250, Loss: 1.3562, Val Loss: 1.3777\n",
            "Epoch 50/250, Loss: 1.3052, Val Loss: 1.3807\n",
            "Epoch 51/250, Loss: 1.2985, Val Loss: 1.3747\n",
            "Epoch 52/250, Loss: 1.2946, Val Loss: 1.3646\n",
            "Epoch 53/250, Loss: 1.2978, Val Loss: 1.3614\n",
            "Epoch 54/250, Loss: 1.2880, Val Loss: 1.3610\n",
            "Epoch 55/250, Loss: 1.2908, Val Loss: 1.3554\n",
            "Epoch 56/250, Loss: 1.2842, Val Loss: 1.3450\n",
            "Epoch 57/250, Loss: 1.2846, Val Loss: 1.3633\n",
            "Epoch 58/250, Loss: 1.2872, Val Loss: 1.3650\n",
            "Epoch 59/250, Loss: 1.2821, Val Loss: 1.3769\n",
            "Epoch 60/250, Loss: 1.2853, Val Loss: 1.3599\n",
            "Epoch 61/250, Loss: 1.2789, Val Loss: 1.3678\n",
            "Epoch 62/250, Loss: 1.2788, Val Loss: 1.3620\n",
            "Epoch 63/250, Loss: 1.2509, Val Loss: 1.3665\n",
            "Epoch 64/250, Loss: 1.2487, Val Loss: 1.3587\n",
            "Epoch 65/250, Loss: 1.2449, Val Loss: 1.3533\n",
            "Epoch 66/250, Loss: 1.2418, Val Loss: 1.3701\n",
            "Early stopping triggered.\n",
            "Accuracy: 54.97%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=RMSProp, epochs=350\n",
            "Evaluating with params: {'epochs': 350, 'kernel_size': 3, 'optimizer_type': 'RMSProp', 'pooling_type': 'max'}\n",
            "Epoch 1/350, Loss: 6.7804, Val Loss: 2.0667\n",
            "Epoch 2/350, Loss: 2.0365, Val Loss: 1.8549\n",
            "Epoch 3/350, Loss: 1.8896, Val Loss: 1.7473\n",
            "Epoch 4/350, Loss: 1.8465, Val Loss: 1.7394\n",
            "Epoch 5/350, Loss: 1.8015, Val Loss: 1.6864\n",
            "Epoch 6/350, Loss: 1.7767, Val Loss: 1.6543\n",
            "Epoch 7/350, Loss: 1.7657, Val Loss: 1.6771\n",
            "Epoch 8/350, Loss: 1.7550, Val Loss: 1.6684\n",
            "Epoch 9/350, Loss: 1.7406, Val Loss: 1.6131\n",
            "Epoch 10/350, Loss: 1.7323, Val Loss: 1.6600\n",
            "Epoch 11/350, Loss: 1.7453, Val Loss: 1.6532\n",
            "Epoch 12/350, Loss: 1.7322, Val Loss: 1.6252\n",
            "Epoch 13/350, Loss: 1.7348, Val Loss: 1.6624\n",
            "Epoch 14/350, Loss: 1.7392, Val Loss: 1.7237\n",
            "Epoch 15/350, Loss: 1.7454, Val Loss: 1.6853\n",
            "Epoch 16/350, Loss: 1.6366, Val Loss: 1.5478\n",
            "Epoch 17/350, Loss: 1.6080, Val Loss: 1.5796\n",
            "Epoch 18/350, Loss: 1.5953, Val Loss: 1.5212\n",
            "Epoch 19/350, Loss: 1.5843, Val Loss: 1.5128\n",
            "Epoch 20/350, Loss: 1.5688, Val Loss: 1.5272\n",
            "Epoch 21/350, Loss: 1.5617, Val Loss: 1.4915\n",
            "Epoch 22/350, Loss: 1.5453, Val Loss: 1.5457\n",
            "Epoch 23/350, Loss: 1.5481, Val Loss: 1.5189\n",
            "Epoch 24/350, Loss: 1.5414, Val Loss: 1.5216\n",
            "Epoch 25/350, Loss: 1.5304, Val Loss: 1.5086\n",
            "Epoch 26/350, Loss: 1.5249, Val Loss: 1.6149\n",
            "Epoch 27/350, Loss: 1.5218, Val Loss: 1.5058\n",
            "Epoch 28/350, Loss: 1.4452, Val Loss: 1.4636\n",
            "Epoch 29/350, Loss: 1.4317, Val Loss: 1.4730\n",
            "Epoch 30/350, Loss: 1.4192, Val Loss: 1.4761\n",
            "Epoch 31/350, Loss: 1.4154, Val Loss: 1.4282\n",
            "Epoch 32/350, Loss: 1.4160, Val Loss: 1.4543\n",
            "Epoch 33/350, Loss: 1.4083, Val Loss: 1.4541\n",
            "Epoch 34/350, Loss: 1.4007, Val Loss: 1.4710\n",
            "Epoch 35/350, Loss: 1.3971, Val Loss: 1.4883\n",
            "Epoch 36/350, Loss: 1.3963, Val Loss: 1.4438\n",
            "Epoch 37/350, Loss: 1.3863, Val Loss: 1.4466\n",
            "Epoch 38/350, Loss: 1.3419, Val Loss: 1.4551\n",
            "Epoch 39/350, Loss: 1.3303, Val Loss: 1.4211\n",
            "Epoch 40/350, Loss: 1.3295, Val Loss: 1.4299\n",
            "Epoch 41/350, Loss: 1.3189, Val Loss: 1.4341\n",
            "Epoch 42/350, Loss: 1.3203, Val Loss: 1.4475\n",
            "Epoch 43/350, Loss: 1.3197, Val Loss: 1.4585\n",
            "Epoch 44/350, Loss: 1.3164, Val Loss: 1.4448\n",
            "Epoch 45/350, Loss: 1.3045, Val Loss: 1.4606\n",
            "Epoch 46/350, Loss: 1.2861, Val Loss: 1.4406\n",
            "Epoch 47/350, Loss: 1.2772, Val Loss: 1.4334\n",
            "Epoch 48/350, Loss: 1.2737, Val Loss: 1.4430\n",
            "Epoch 49/350, Loss: 1.2728, Val Loss: 1.4324\n",
            "Early stopping triggered.\n",
            "Accuracy: 51.75%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=Adam, epochs=5\n",
            "Evaluating with params: {'epochs': 5, 'kernel_size': 3, 'optimizer_type': 'Adam', 'pooling_type': 'max'}\n",
            "Epoch 1/5, Loss: 1.5339, Val Loss: 1.1692\n",
            "Epoch 2/5, Loss: 1.2079, Val Loss: 1.0505\n",
            "Epoch 3/5, Loss: 1.0752, Val Loss: 0.9437\n",
            "Epoch 4/5, Loss: 0.9776, Val Loss: 0.9165\n",
            "Epoch 5/5, Loss: 0.9090, Val Loss: 0.8678\n",
            "Accuracy: 69.98%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=Adam, epochs=50\n",
            "Evaluating with params: {'epochs': 50, 'kernel_size': 3, 'optimizer_type': 'Adam', 'pooling_type': 'max'}\n",
            "Epoch 1/50, Loss: 1.5796, Val Loss: 1.2497\n",
            "Epoch 2/50, Loss: 1.2757, Val Loss: 1.0699\n",
            "Epoch 3/50, Loss: 1.1317, Val Loss: 1.0000\n",
            "Epoch 4/50, Loss: 1.0395, Val Loss: 0.9476\n",
            "Epoch 5/50, Loss: 0.9719, Val Loss: 0.9240\n",
            "Epoch 6/50, Loss: 0.9090, Val Loss: 0.8814\n",
            "Epoch 7/50, Loss: 0.8709, Val Loss: 0.8888\n",
            "Epoch 8/50, Loss: 0.8243, Val Loss: 0.8606\n",
            "Epoch 9/50, Loss: 0.7893, Val Loss: 0.9141\n",
            "Epoch 10/50, Loss: 0.7534, Val Loss: 0.8791\n",
            "Epoch 11/50, Loss: 0.7296, Val Loss: 0.8917\n",
            "Epoch 12/50, Loss: 0.6961, Val Loss: 0.8581\n",
            "Epoch 13/50, Loss: 0.6754, Val Loss: 0.8846\n",
            "Epoch 14/50, Loss: 0.6457, Val Loss: 0.8822\n",
            "Epoch 15/50, Loss: 0.6265, Val Loss: 0.9100\n",
            "Epoch 16/50, Loss: 0.6068, Val Loss: 0.9511\n",
            "Epoch 17/50, Loss: 0.5904, Val Loss: 0.9482\n",
            "Epoch 18/50, Loss: 0.5744, Val Loss: 0.9253\n",
            "Epoch 19/50, Loss: 0.4893, Val Loss: 0.9611\n",
            "Epoch 20/50, Loss: 0.4638, Val Loss: 0.9873\n",
            "Epoch 21/50, Loss: 0.4431, Val Loss: 0.9874\n",
            "Epoch 22/50, Loss: 0.4287, Val Loss: 1.0245\n",
            "Early stopping triggered.\n",
            "Accuracy: 72.18%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=Adam, epochs=100\n",
            "Evaluating with params: {'epochs': 100, 'kernel_size': 3, 'optimizer_type': 'Adam', 'pooling_type': 'max'}\n",
            "Epoch 1/100, Loss: 1.5240, Val Loss: 1.1652\n",
            "Epoch 2/100, Loss: 1.1973, Val Loss: 1.0175\n",
            "Epoch 3/100, Loss: 1.0585, Val Loss: 0.9569\n",
            "Epoch 4/100, Loss: 0.9653, Val Loss: 0.9080\n",
            "Epoch 5/100, Loss: 0.8998, Val Loss: 0.8848\n",
            "Epoch 6/100, Loss: 0.8360, Val Loss: 0.8510\n",
            "Epoch 7/100, Loss: 0.7839, Val Loss: 0.8760\n",
            "Epoch 8/100, Loss: 0.7350, Val Loss: 0.8524\n",
            "Epoch 9/100, Loss: 0.6914, Val Loss: 0.8523\n",
            "Epoch 10/100, Loss: 0.6516, Val Loss: 0.8682\n",
            "Epoch 11/100, Loss: 0.6231, Val Loss: 0.8665\n",
            "Epoch 12/100, Loss: 0.5898, Val Loss: 0.8841\n",
            "Epoch 13/100, Loss: 0.4884, Val Loss: 0.8943\n",
            "Epoch 14/100, Loss: 0.4522, Val Loss: 0.9234\n",
            "Epoch 15/100, Loss: 0.4324, Val Loss: 0.9659\n",
            "Epoch 16/100, Loss: 0.4095, Val Loss: 0.9408\n",
            "Early stopping triggered.\n",
            "Accuracy: 72.26%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=Adam, epochs=250\n",
            "Evaluating with params: {'epochs': 250, 'kernel_size': 3, 'optimizer_type': 'Adam', 'pooling_type': 'max'}\n",
            "Epoch 1/250, Loss: 1.5736, Val Loss: 1.2978\n",
            "Epoch 2/250, Loss: 1.2592, Val Loss: 1.0648\n",
            "Epoch 3/250, Loss: 1.1310, Val Loss: 0.9722\n",
            "Epoch 4/250, Loss: 1.0385, Val Loss: 0.9222\n",
            "Epoch 5/250, Loss: 0.9652, Val Loss: 0.9010\n",
            "Epoch 6/250, Loss: 0.9180, Val Loss: 0.8862\n",
            "Epoch 7/250, Loss: 0.8641, Val Loss: 0.8720\n",
            "Epoch 8/250, Loss: 0.8194, Val Loss: 0.8496\n",
            "Epoch 9/250, Loss: 0.7756, Val Loss: 0.8521\n",
            "Epoch 10/250, Loss: 0.7451, Val Loss: 0.8365\n",
            "Epoch 11/250, Loss: 0.7148, Val Loss: 0.8579\n",
            "Epoch 12/250, Loss: 0.6891, Val Loss: 0.8815\n",
            "Epoch 13/250, Loss: 0.6603, Val Loss: 0.8918\n",
            "Epoch 14/250, Loss: 0.6444, Val Loss: 0.8894\n",
            "Epoch 15/250, Loss: 0.6184, Val Loss: 0.8946\n",
            "Epoch 16/250, Loss: 0.5972, Val Loss: 0.9597\n",
            "Epoch 17/250, Loss: 0.5123, Val Loss: 0.9380\n",
            "Epoch 18/250, Loss: 0.4849, Val Loss: 0.9424\n",
            "Epoch 19/250, Loss: 0.4648, Val Loss: 0.9635\n",
            "Epoch 20/250, Loss: 0.4541, Val Loss: 0.9813\n",
            "Early stopping triggered.\n",
            "Accuracy: 72.69%\n",
            "Running experiment with kernel_size=3, pooling_type=max, optimizer=Adam, epochs=350\n",
            "Evaluating with params: {'epochs': 350, 'kernel_size': 3, 'optimizer_type': 'Adam', 'pooling_type': 'max'}\n",
            "Epoch 1/350, Loss: 1.5928, Val Loss: 1.2296\n",
            "Epoch 2/350, Loss: 1.2681, Val Loss: 1.0862\n",
            "Epoch 3/350, Loss: 1.1356, Val Loss: 0.9696\n",
            "Epoch 4/350, Loss: 1.0464, Val Loss: 0.9534\n",
            "Epoch 5/350, Loss: 0.9691, Val Loss: 0.9024\n",
            "Epoch 6/350, Loss: 0.9114, Val Loss: 0.8871\n",
            "Epoch 7/350, Loss: 0.8630, Val Loss: 0.8649\n",
            "Epoch 8/350, Loss: 0.8222, Val Loss: 0.8562\n",
            "Epoch 9/350, Loss: 0.7854, Val Loss: 0.8776\n",
            "Epoch 10/350, Loss: 0.7499, Val Loss: 0.8783\n",
            "Epoch 11/350, Loss: 0.7202, Val Loss: 0.8890\n",
            "Epoch 12/350, Loss: 0.6806, Val Loss: 0.8671\n",
            "Epoch 13/350, Loss: 0.6639, Val Loss: 0.8996\n",
            "Epoch 14/350, Loss: 0.6363, Val Loss: 0.8924\n",
            "Epoch 15/350, Loss: 0.5528, Val Loss: 0.9119\n",
            "Epoch 16/350, Loss: 0.5187, Val Loss: 0.9435\n",
            "Epoch 17/350, Loss: 0.5006, Val Loss: 0.9469\n",
            "Epoch 18/350, Loss: 0.4888, Val Loss: 0.9399\n",
            "Early stopping triggered.\n",
            "Accuracy: 72.20%\n",
            "Running experiment with kernel_size=3, pooling_type=avg, optimizer=SGD, epochs=5\n",
            "Evaluating with params: {'epochs': 5, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'avg'}\n",
            "Epoch 1/5, Loss: 1.7243, Val Loss: 1.3491\n",
            "Epoch 2/5, Loss: 1.3777, Val Loss: 1.2009\n",
            "Epoch 3/5, Loss: 1.2286, Val Loss: 1.0767\n",
            "Epoch 4/5, Loss: 1.1206, Val Loss: 1.0058\n",
            "Epoch 5/5, Loss: 1.0306, Val Loss: 0.9546\n",
            "Accuracy: 65.90%\n",
            "Running experiment with kernel_size=3, pooling_type=avg, optimizer=SGD, epochs=50\n",
            "Evaluating with params: {'epochs': 50, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'avg'}\n",
            "Epoch 1/50, Loss: 1.7449, Val Loss: 1.4014\n",
            "Epoch 2/50, Loss: 1.4016, Val Loss: 1.2420\n",
            "Epoch 3/50, Loss: 1.2435, Val Loss: 1.0919\n",
            "Epoch 4/50, Loss: 1.1236, Val Loss: 1.0559\n",
            "Epoch 5/50, Loss: 1.0373, Val Loss: 0.9695\n",
            "Epoch 6/50, Loss: 0.9638, Val Loss: 0.9139\n",
            "Epoch 7/50, Loss: 0.8923, Val Loss: 0.8854\n",
            "Epoch 8/50, Loss: 0.8349, Val Loss: 0.8667\n",
            "Epoch 9/50, Loss: 0.7835, Val Loss: 0.8574\n",
            "Epoch 10/50, Loss: 0.7364, Val Loss: 0.8585\n",
            "Epoch 11/50, Loss: 0.6906, Val Loss: 0.8560\n",
            "Epoch 12/50, Loss: 0.6530, Val Loss: 0.8544\n",
            "Epoch 13/50, Loss: 0.6191, Val Loss: 0.8706\n",
            "Epoch 14/50, Loss: 0.5795, Val Loss: 0.8973\n",
            "Epoch 15/50, Loss: 0.5471, Val Loss: 0.9180\n",
            "Epoch 16/50, Loss: 0.5203, Val Loss: 0.8988\n",
            "Epoch 17/50, Loss: 0.4949, Val Loss: 0.9123\n",
            "Epoch 18/50, Loss: 0.4674, Val Loss: 0.9394\n",
            "Epoch 19/50, Loss: 0.3585, Val Loss: 0.9371\n",
            "Epoch 20/50, Loss: 0.3181, Val Loss: 0.9814\n",
            "Epoch 21/50, Loss: 0.2952, Val Loss: 0.9902\n",
            "Epoch 22/50, Loss: 0.2676, Val Loss: 1.0339\n",
            "Early stopping triggered.\n",
            "Accuracy: 73.26%\n",
            "Running experiment with kernel_size=3, pooling_type=avg, optimizer=SGD, epochs=100\n",
            "Evaluating with params: {'epochs': 100, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'avg'}\n",
            "Epoch 1/100, Loss: 1.7250, Val Loss: 1.4058\n",
            "Epoch 2/100, Loss: 1.3794, Val Loss: 1.1939\n",
            "Epoch 3/100, Loss: 1.2279, Val Loss: 1.0806\n",
            "Epoch 4/100, Loss: 1.1200, Val Loss: 1.0166\n",
            "Epoch 5/100, Loss: 1.0370, Val Loss: 0.9735\n",
            "Epoch 6/100, Loss: 0.9542, Val Loss: 0.9306\n",
            "Epoch 7/100, Loss: 0.8886, Val Loss: 0.8836\n",
            "Epoch 8/100, Loss: 0.8312, Val Loss: 0.9105\n",
            "Epoch 9/100, Loss: 0.7768, Val Loss: 0.8529\n",
            "Epoch 10/100, Loss: 0.7285, Val Loss: 0.8397\n",
            "Epoch 11/100, Loss: 0.6777, Val Loss: 0.8492\n",
            "Epoch 12/100, Loss: 0.6363, Val Loss: 0.8406\n",
            "Epoch 13/100, Loss: 0.5999, Val Loss: 0.8697\n",
            "Epoch 14/100, Loss: 0.5598, Val Loss: 0.8486\n",
            "Epoch 15/100, Loss: 0.5318, Val Loss: 0.8732\n",
            "Epoch 16/100, Loss: 0.4992, Val Loss: 0.9112\n",
            "Epoch 17/100, Loss: 0.3931, Val Loss: 0.8679\n",
            "Epoch 18/100, Loss: 0.3501, Val Loss: 0.9058\n",
            "Epoch 19/100, Loss: 0.3164, Val Loss: 0.9500\n",
            "Epoch 20/100, Loss: 0.3041, Val Loss: 0.9339\n",
            "Early stopping triggered.\n",
            "Accuracy: 73.28%\n",
            "Running experiment with kernel_size=3, pooling_type=avg, optimizer=SGD, epochs=250\n",
            "Evaluating with params: {'epochs': 250, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'avg'}\n",
            "Epoch 1/250, Loss: 1.7397, Val Loss: 1.3986\n",
            "Epoch 2/250, Loss: 1.3845, Val Loss: 1.1902\n",
            "Epoch 3/250, Loss: 1.2365, Val Loss: 1.1159\n",
            "Epoch 4/250, Loss: 1.1310, Val Loss: 1.0328\n",
            "Epoch 5/250, Loss: 1.0532, Val Loss: 0.9943\n",
            "Epoch 6/250, Loss: 0.9804, Val Loss: 0.9675\n",
            "Epoch 7/250, Loss: 0.9150, Val Loss: 0.9147\n",
            "Epoch 8/250, Loss: 0.8583, Val Loss: 0.8800\n",
            "Epoch 9/250, Loss: 0.7975, Val Loss: 0.8719\n",
            "Epoch 10/250, Loss: 0.7449, Val Loss: 0.8836\n",
            "Epoch 11/250, Loss: 0.7068, Val Loss: 0.8687\n",
            "Epoch 12/250, Loss: 0.6613, Val Loss: 0.8665\n",
            "Epoch 13/250, Loss: 0.6240, Val Loss: 0.9108\n",
            "Epoch 14/250, Loss: 0.5792, Val Loss: 0.8998\n",
            "Epoch 15/250, Loss: 0.5531, Val Loss: 0.8937\n",
            "Epoch 16/250, Loss: 0.5264, Val Loss: 0.9505\n",
            "Epoch 17/250, Loss: 0.4935, Val Loss: 0.9383\n",
            "Epoch 18/250, Loss: 0.4692, Val Loss: 0.9245\n",
            "Epoch 19/250, Loss: 0.3622, Val Loss: 0.9662\n",
            "Epoch 20/250, Loss: 0.3213, Val Loss: 0.9786\n",
            "Epoch 21/250, Loss: 0.2933, Val Loss: 1.0457\n",
            "Epoch 22/250, Loss: 0.2827, Val Loss: 1.0544\n",
            "Early stopping triggered.\n",
            "Accuracy: 72.58%\n",
            "Running experiment with kernel_size=3, pooling_type=avg, optimizer=SGD, epochs=350\n",
            "Evaluating with params: {'epochs': 350, 'kernel_size': 3, 'optimizer_type': 'SGD', 'pooling_type': 'avg'}\n"
          ]
        }
      ]
    }
  ]
}